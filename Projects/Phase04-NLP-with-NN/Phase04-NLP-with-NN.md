## پردازش زبان طبیعی با یادگیری عمیق
در فاز قبلی مقدمات پردازش زبان طبیعی آشنا شدیم. فهمیدیم nlp چیه، چه مراحلی داره و چه کارایی میشه باهاش کرد. 
حالا نوبت این رسیده که آموخته هامون رو ترکیب کنیم. یعنی اون چیزایی که از شبکه های عصبی فهمیدیم رو استفاده کنیم تا مدل های کاربردی برای پردازش زبان طبیعی بسازیم.
شبکه های عصبی بازگشتی بیشترین کاربرد رو در NLP دارن و لازمه  اگه چیزی رو فراموش کردی، یه مروری بکنی.

## طبقه بندی متن
فاز قبلی هم این پروژه رو انجام دادی و آشنا شدی که هدف چیه. این دفعه می خوایم مدل رو بر اساس شبکه های عصبی بسازیم. برای آموزش، از لینک زیر استفاده کن:

[کلاس بندی متن با پایتورچ](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)

حالا که یاد گرفتی این کار چطوری انجام میشه، برای مجموعه دادگان دیجی مگ که توی پوشه داده هست، این کارو تکرار کن. این داده ها دارای 8515 مقاله در این 7 کلاس هستند:

| Label |	Count |
|.......|.......|
| Video Games	| 1967 |
| Shopping Guide	| 125 |
| Health Beauty |	1610 |
| Science Technology	| 2772 |
| General	| 120 |
| Art Cinema	| 1667 |
| Books Literature	| 254 |

حالا که برای این مجموعه داده ها آموزش دادی و مدلت میتونه متن کلاس بندی کنه، و همچنین قبلتر با یادگیری انتقالی آشنا شدی، یادگیری انتقالی انجام بده برای کلاس بندی متن برای مجموعه دادگان خبری. این مجموعه داده ها هم توی پوشه داده ها هست.

توزیع داده ها هم به این شکله:
Label	Count
Social	2170
Economic	1564
International	1975
Political	2269
Science Technology	2436
Cultural Art	2558
Sport	1381
Medical	2085
