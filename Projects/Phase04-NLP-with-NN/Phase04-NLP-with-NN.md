<div dir="rtl" align='right'>

## پردازش زبان طبیعی با یادگیری عمیق
در فاز قبلی مقدمات پردازش زبان طبیعی آشنا شدیم. فهمیدیم nlp چیه، چه مراحلی داره و چه کارایی میشه باهاش کرد. 
حالا نوبت این رسیده که آموخته هامون رو ترکیب کنیم. یعنی اون چیزایی که از شبکه های عصبی فهمیدیم رو استفاده کنیم تا مدل های کاربردی برای پردازش زبان طبیعی بسازیم.
شبکه های عصبی بازگشتی بیشترین کاربرد رو در NLP دارن و لازمه  اگه چیزی رو فراموش کردی، یه مروری بکنی.

## طبقه بندی متن
فاز قبلی هم این پروژه رو انجام دادی و آشنا شدی که هدف چیه. این دفعه می خوایم مدل رو بر اساس شبکه های عصبی بسازیم. برای آموزش، از لینک زیر استفاده کن:

[کلاس بندی متن با پایتورچ](https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html)

حالا که یاد گرفتی این کار چطوری انجام میشه، برای مجموعه دادگان دیجی مگ که توی پوشه داده هست، این کارو تکرار کن. این داده ها دارای 8515 مقاله در این 7 کلاس هستند:

| Label |	Count |
|-------|-------|
| Video Games	| 1967 |
| Shopping Guide	| 125 |
| Health Beauty |	1610 |
| Science Technology	| 2772 |
| General	| 120 |
| Art Cinema	| 1667 |
| Books Literature	| 254 |

حالا که برای این مجموعه داده ها آموزش دادی و مدلت میتونه متن کلاس بندی کنه، و همچنین قبلتر با یادگیری انتقالی آشنا شدی، یادگیری انتقالی انجام بده برای کلاس بندی متن برای مجموعه دادگان خبری. این مجموعه داده ها هم توی پوشه داده ها هست.

توزیع داده ها هم به این شکله:
| Label |	Count |
|-------|-------|
| Social	| 2170 |
| Economic |	1564 |
| International | 1975 |
| Political |	2269 |
| Science Technology	| 2436 |
| Cultural Art	| 2558 |
| Sport |	1381 |
| Medical |	2085 |

## تحلیل احساسات
  تحلیل احساسات هم تسکی مشابه کلاس بندی هست. ولی اینجا 3 تا کلاس مثبت، منفی و خنثی داریم. یک روش ساده برای طبقه بندی احساسات یا قطبیت جمله، استفاده از قطبیت تک تک کلمات برای رسیدن به قطبیت کلی هست. فایل PerSent.xlsx شامل تعداد زیادی کلمه به همراه قطبیت اونا هست. یه روشی غیر شبکه عصبی پیاده سازی بکن که از قطبیت هر کلمه استفاده کنه برای رسیدن به قطبیت جمله. از فایل Labeled-Sentences.xlsx هم به عنوان داده ی آموزشی و تستی استفاده کن. میتونی به درصد 70 به 30 داده ها رو به قسمت آموزش و تست تقسیم کنی.
 
  به این سوالات فکر کن و توی قسمت ایشوها جواب بده:
  1. این روش چه ایراداتی داره؟
  2.  اگر در جمله ای که میخواهیم قطبیت آن مشخص کنیم، کلمه ای بود که قبلا در دایره واژگان قطبیت های ما نبود، چه کاری 
  انجام میدی؟
  3. علاوه بر روش یا روش هایی که پیاده سازی کردی، چه روش دیگه ای به ذهنت میرسه؟

خب الان بریم سراغ ساخت کلاس بند احساسات با استفاده از شبکه های عصبی. اولین مجموعه دادگان، همون مجموعه قبلی یعنی Labeled-Sentences.xlsx هست. با همون میزان به قسمت های آموزشی و تست تقسیم کن. اول یک شبکه بازگشتی آموزش بده برای طبقه بندی احساسات این داده ها.    
   اگه نیاز به آموزش داری، از این لینک ببین:
  [آموزش قدم به قدم تحلیل احساسات با شبکه های عصبی](https://towardsdatascience.com/sentiment-analysis-using-lstm-step-by-step-50d074f09948)

  به این سوالات هم فکر کن و توی ایشوها جواب بده:
  1. نتایج این شبکه رو با نتایجی که از روش یا روش های غیر شبکه ای بدست آوردی مقایسه کن
  2. روش شبکه عصبی بازگشتی بهتره یا روش غیر شبکه ای؟ چرا؟
  
  علاوه بر شبکه ی عصبی بازگشتی، با شبکه عصبی کانولوشنی هم یک طبقه بند احساسات بساز.
  
  به این سوالات هم توی ایشوها جواب بده»
  1. نتایج این چند روش رو با هم مقایسه کن
  2. کدوم شبکه ی عصبی بهتره برای طبقه بندی احساسات
  3. چطوری میتونی میزان قطبیت جمله رو بسنجی؟ یعنی یه عدد بین -1 تا +1 بدی که میزان مثبت یا منفی بودنش رو نشون بده؟

## تبدیل کلمه به بردار
خب دیدی که شبکه های عصبی برای پردازش متن، ابتدا اون ها رو تبدیل به بردار میکنن.  یک روش که دیدی این بود که برای هر کلمه یک شماره اختصاص بدی. دیدی که شبکه عصبی یک لایه Embedding داره که بردارهای ورودی پردازش میکنه و نمایش جدیدی از اونها ارائه میکنه. میتونیم امبدینگ هر چیزی رو بدست بیاریم. مثلا امبدینگ کلمه، جمله، تصویر، صدا، ویدئو ... . مثلا توی Word Embedding، یک بردار میسازی که مشخصات اون کلمه رو بیان میکنه. مثلا میخوایم یک نمایش برداری برای کلمات داشته باشیم، چند تا ویژگی رو در نظر میگیرم:

|کلمه|زنده|شیء|بزرگ|خوردنی|
|-------|----|---|-----|----|
|مرد|1|-1|1|-1|
|پسر|1|-1|-1|-1|
|ماهی|1|-1|-1|1|
|خودکار|-1|1|-1|-1|


توی جدول بالایی یه سری ویژگی مشخص کردیم و برای هر کلمه مقدار اون ویژگی رو تعیین کردیم. اگه کلمه ای اون ویژگی رو داشت مقدارش +1 میشه و اگه نداشت، مقدار اون ویژگی -1 میشه. با این حساب، میتونیم کلمه ی مرد رو با این بردار نمایش بدیم:

مرد=[1,1-,1,-1]

با این بردارها میتونیم تشابه دو کلمه رو با استفاده از ضرب داخلی بدست بیاریم. هر چقدر میزان این ضرب داخلی زیاد بود، یعنی دو کلمه مشابه هستند. مثلا ضرب داخلی کلمه مرد و پسر میشه 2. ضرب داخلی پسر و خودکار میشه صفر. یعنی تشابه مرد و پسر بیشتر از تشابه پسر و خودرکار هست!

حتی میشه با این بردارها عملیات ریاضی انجام داد. مثلا اون ها رو از هم کرد کرد تا تفاوتشون رو دید. مثلا اگه بردار کلمه مرد رو از پسر کم کنیم، همه ی درایه ها بجز ویژگی بزرگ بودن صفر میشه. یعنی تفاوت مرد و پسر در بزرگ بودنشون هست!

ولی تو جدول بالایی یک نکته ای هست، ضرب داخلی کلمه پسر و ماهی هم میشه 2! یعنی همونقدر که پسر به مرد شبیهه، به ماهی هم شبیهه؟! اینجا دو تا ایراد هست: یکی اینکه تعداد ویژگی های کمی استفاده کردیم، دومی هم اینکه مقدار ویژگی ها رو فقط 1 و -1 در نظر گرفتیم. اگه این دو مورد رو برطرف کنیم، امبدینگ بهتری میتونیم بدست بیاریم.

حالا برای این همه کلمه چطوری امبدینگ ایجاد کنیم؟ امکان نداره که بشینیم تک تک برای هر کلمه، ویژگی هاش رو بنویسیم! پس باید از یه روش یادگیری ماشینی استفاده کنیم. برای اینکه بدونی چطوری این Embedding ها بدست میاد، لینک زیر رو ببین:
[آشنایی بیشتر با Embedding](https://machinelearningmastery.com/what-are-word-embeddings/)

* توی شبکه ی عصبی یک لایه Embedding گذاشتی. از طریق اون لایه، امبدینگ چند تا کلمه دلخواه رو بدست بیار و تشابهشون رو بررسی کن.
* Gensim یک کتابخونه ست که میتونی باهاش Word Embedding بدست بیاری. توی لینک زیر نحوه استفاده ازش اومده. برای مجموعه اخبار روزنامه همشهری، Word Embedding  رو بدست بیار.
* حالا که Word Embedding رو بدست آوردی، از اون توی شبکه ی عصبی استفاده کن. یعنی بجای اینکه کلمات رو با عدد نشون بدی و وارد شبکه کنی، اونا رو با امبدینگشون نمایش بده و وارد شبکه کن. نتایج رو با حالت قبلی بررسی کن و گزارش بده.